{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNfi/ZBx1oHH+bbyVcl8l1d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acram002/AI-Driven-Recipe-Suggestion-System/blob/main/spoonacularAPI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "5bf6609405mshe61b903936f23cep1fd1b6jsn1ecaaf102007"
      ],
      "metadata": {
        "id": "hIZGB_CSQBGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68RYJ-A6gMxX"
      },
      "outputs": [],
      "source": [
        "# random\n",
        "import http.client\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Spoonacular API and RapidAPI Configuration\n",
        "RAPIDAPI_KEY = \"5bf6609405mshe61b903936f23cep1fd1b6jsn1ecaaf102007\"  # Replace with your RapidAPI key\n",
        "\n",
        "# Function to query Spoonacular API for recipes\n",
        "def get_recipes(query, diet, intolerances, include_ingredients, exclude_ingredients, num_recipes=100):\n",
        "    conn = http.client.HTTPSConnection(\"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\")\n",
        "\n",
        "    headers = {\n",
        "        'x-rapidapi-key': RAPIDAPI_KEY,\n",
        "        'x-rapidapi-host': \"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\"\n",
        "    }\n",
        "\n",
        "    # Pagination setup: start with the first page\n",
        "    offset = 0\n",
        "    all_recipes = []\n",
        "\n",
        "    while len(all_recipes) < num_recipes:\n",
        "        # API endpoint parameters\n",
        "        url = f\"/recipes/complexSearch?query={query}&diet={diet}&intolerances={intolerances}&includeIngredients={include_ingredients}&excludeIngredients={exclude_ingredients}&instructionsRequired=true&addRecipeInformation=true&number={num_recipes}\"\n",
        "\n",
        "        conn.request(\"GET\", url, headers=headers)\n",
        "        res = conn.getresponse()\n",
        "        data = res.read()\n",
        "\n",
        "        recipes_data = json.loads(data.decode(\"utf-8\"))\n",
        "\n",
        "        # If no recipes found, break the loop\n",
        "        if \"results\" not in recipes_data or not recipes_data[\"results\"]:\n",
        "            break\n",
        "\n",
        "        all_recipes.extend(recipes_data[\"results\"])\n",
        "        offset += 10  # Increment the offset to get the next batch of results\n",
        "\n",
        "        # Break the loop if we have enough recipes\n",
        "        if len(all_recipes) >= num_recipes:\n",
        "            break\n",
        "\n",
        "    return all_recipes[:num_recipes]  # Limit to the requested number of recipes\n",
        "\n",
        "# Function to process and store recipe data\n",
        "def process_recipes(recipes_data, allergies, dietary_preferences):\n",
        "    recipe_list = []\n",
        "\n",
        "    for recipe in recipes_data:\n",
        "        title = recipe[\"title\"]\n",
        "\n",
        "        # Extract ingredients and instructions\n",
        "        ingredients = []\n",
        "        for ingredient in recipe.get(\"extendedIngredients\", []):\n",
        "            ingredients.append(ingredient[\"name\"])\n",
        "\n",
        "        # Check if instructions are available\n",
        "        instructions = recipe.get(\"instructions\", \"No instructions provided\")\n",
        "\n",
        "        # Ensure allergies and dietary preferences are included, even if missing in data\n",
        "        recipe_allergies = allergies if allergies else \"Not specified\"\n",
        "        recipe_dietary_preferences = dietary_preferences if dietary_preferences else \"Not specified\"\n",
        "\n",
        "        # Store the recipe data\n",
        "        recipe_list.append({\n",
        "            \"title\": title,\n",
        "            \"ingredients\": ingredients if ingredients else [\"No ingredients provided\"],\n",
        "            \"instructions\": instructions,\n",
        "            \"allergies\": recipe_allergies,\n",
        "            \"dietary_preferences\": recipe_dietary_preferences\n",
        "        })\n",
        "\n",
        "    return recipe_list\n",
        "\n",
        "# Define the input parameters\n",
        "ingredient_query = \"salad\"  # Example query\n",
        "dietary_preferences = \"vegetarian\"  # Example dietary preference (can also be \"vegan\", \"gluten free\", etc.)\n",
        "allergies = \"gluten\"  # Example allergens (e.g., \"gluten\", \"dairy\", \"peanut\")\n",
        "include_ingredients = \"cheese,nuts\"  # Ingredients that must be included\n",
        "exclude_ingredients = \"eggs\"  # Ingredients that must be excluded\n",
        "\n",
        "# Fetch recipes from Spoonacular API\n",
        "recipes_data = get_recipes(ingredient_query, dietary_preferences, allergies, include_ingredients, exclude_ingredients, num_recipes=10)\n",
        "\n",
        "# Process the recipes data\n",
        "if recipes_data:\n",
        "    recipes = process_recipes(recipes_data, allergies, dietary_preferences)\n",
        "\n",
        "    # Convert the list to a DataFrame\n",
        "    df = pd.DataFrame(recipes)\n",
        "\n",
        "    # Ensure the directory exists before saving the file\n",
        "    save_path = \"/content/drive/MyDrive/spoonacular_recipes_dataset.csv\"\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "    # Save dataset to a CSV file\n",
        "    df.to_csv(save_path, index=False)\n",
        "    print(f\"Dataset created with {len(df)} recipes.\")\n",
        "else:\n",
        "    print(\"No recipes found or there was an error with the API request.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All columns\n",
        "import http.client\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Spoonacular API and RapidAPI Configuration\n",
        "RAPIDAPI_KEY = \"5bf6609405mshe61b903936f23cep1fd1b6jsn1ecaaf102007\"  # Replace with your RapidAPI key\n",
        "\n",
        "# Function to query Spoonacular API for recipes\n",
        "def get_recipes(query, diet, intolerances, include_ingredients, exclude_ingredients, num_recipes=5):\n",
        "    conn = http.client.HTTPSConnection(\"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\")\n",
        "\n",
        "    headers = {\n",
        "        'x-rapidapi-key': RAPIDAPI_KEY,\n",
        "        'x-rapidapi-host': \"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\"\n",
        "    }\n",
        "\n",
        "    # API endpoint parameters\n",
        "    url = f\"/recipes/complexSearch?query={query}&diet={diet}&intolerances={intolerances}&includeIngredients={include_ingredients}&excludeIngredients={exclude_ingredients}&instructionsRequired=true&addRecipeInformation=true&number={num_recipes}\"\n",
        "\n",
        "    conn.request(\"GET\", url, headers=headers)\n",
        "\n",
        "    res = conn.getresponse()\n",
        "    data = res.read()\n",
        "\n",
        "    return json.loads(data.decode(\"utf-8\"))\n",
        "\n",
        "# Function to process and store recipe data\n",
        "def process_recipes(recipes_data, allergies, dietary_preferences):\n",
        "    recipe_list = []\n",
        "\n",
        "    for recipe in recipes_data[\"results\"]:\n",
        "        title = recipe[\"title\"]\n",
        "\n",
        "        # Extract ingredients and instructions\n",
        "        ingredients = []\n",
        "        for ingredient in recipe.get(\"analyzedInstructions\", []):\n",
        "            for step in ingredient.get(\"steps\", []):\n",
        "                step_ingredients = [ingredient[\"name\"] for ingredient in step.get(\"ingredients\", [])]\n",
        "                ingredients.extend(step_ingredients)\n",
        "\n",
        "        instructions = []\n",
        "        for instruction in recipe.get(\"analyzedInstructions\", []):\n",
        "            for step in instruction.get(\"steps\", []):\n",
        "                instructions.append(step.get(\"step\", \"No instructions provided\"))\n",
        "\n",
        "        # Store the recipe data\n",
        "        recipe_list.append({\n",
        "            \"title\": title,\n",
        "            \"ingredients\": ingredients,\n",
        "            \"instructions\": \" \".join(instructions) if instructions else \"No instructions provided\",\n",
        "            \"allergies\": allergies,\n",
        "            \"dietary_preferences\": dietary_preferences\n",
        "        })\n",
        "\n",
        "    return recipe_list\n",
        "# EDIT THESE\n",
        "# Define the input parameters\n",
        "ingredient_query = \"\"  # Example query\n",
        "dietary_preferences = \"vegetarian\"  # Example dietary preference (can also be \"vegan\", \"gluten free\", etc.)\n",
        "allergies = \"gluten\"  # Example allergens (e.g., \"gluten\", \"dairy\", \"peanut\")\n",
        "include_ingredients = \"cheese,nuts\"  # Ingredients that must be included\n",
        "exclude_ingredients = \"eggs\"  # Ingredients that must be excluded\n",
        "\n",
        "# Fetch recipes from Spoonacular API\n",
        "recipes_data = get_recipes(ingredient_query, dietary_preferences, allergies, include_ingredients, exclude_ingredients, num_recipes=5)\n",
        "\n",
        "# Process the recipes data\n",
        "if recipes_data:\n",
        "    recipes = process_recipes(recipes_data, allergies, dietary_preferences)\n",
        "\n",
        "    # Convert the list to a DataFrame\n",
        "    df = pd.DataFrame(recipes)\n",
        "\n",
        "    # Save dataset to a CSV file\n",
        "    df.to_csv(\"spoonacular_recipes_dataset1.csv\", index=False)\n",
        "    print(f\"Dataset created with {len(df)} recipes.\")\n",
        "else:\n",
        "    print(\"No recipes found or there was an error with the API request.\")\n"
      ],
      "metadata": {
        "id": "hRc-LHmf67yY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import http.client\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "from urllib.parse import quote_plus\n",
        "\n",
        "# Spoonacular API and RapidAPI Configuration\n",
        "RAPIDAPI_KEY = \"5bf6609405mshe61b903936f23cep1fd1b6jsn1ecaaf102007\"  # Replace with your RapidAPI key\n",
        "\n",
        "# Function to query Spoonacular API for recipes\n",
        "def get_recipes(query, diet, intolerances, include_ingredients, exclude_ingredients, num_recipes=5):\n",
        "    conn = http.client.HTTPSConnection(\"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\")\n",
        "\n",
        "    headers = {\n",
        "        'x-rapidapi-key': RAPIDAPI_KEY,\n",
        "        'x-rapidapi-host': \"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\"\n",
        "    }\n",
        "\n",
        "    # URL encoding to handle spaces and special characters\n",
        "    query = quote_plus(query)\n",
        "    diet = quote_plus(diet)\n",
        "    intolerances = quote_plus(intolerances)\n",
        "    include_ingredients = quote_plus(include_ingredients)\n",
        "    exclude_ingredients = quote_plus(exclude_ingredients)\n",
        "\n",
        "    # Pagination setup: start with the first page\n",
        "    offset = 0\n",
        "    all_recipes = []\n",
        "\n",
        "    while len(all_recipes) < num_recipes:\n",
        "        # API endpoint parameters\n",
        "        url = f\"/recipes/complexSearch?query={query}&diet={diet}&intolerances={intolerances}&includeIngredients={include_ingredients}&excludeIngredients={exclude_ingredients}&instructionsRequired=true&addRecipeInformation=true&number=10&offset={offset}\"\n",
        "\n",
        "        conn.request(\"GET\", url, headers=headers)\n",
        "        res = conn.getresponse()\n",
        "        data = res.read()\n",
        "\n",
        "        recipes_data = json.loads(data.decode(\"utf-8\"))\n",
        "\n",
        "        # If no recipes found, break the loop\n",
        "        if \"results\" not in recipes_data or not recipes_data[\"results\"]:\n",
        "            break\n",
        "\n",
        "        all_recipes.extend(recipes_data[\"results\"])\n",
        "        offset += 10  # Increment the offset to get the next batch of results\n",
        "\n",
        "        # Break the loop if we have enough recipes\n",
        "        if len(all_recipes) >= num_recipes:\n",
        "            break\n",
        "\n",
        "    return all_recipes[:num_recipes]  # Limit to the requested number of recipes\n",
        "\n",
        "# Function to process and store recipe data\n",
        "def process_recipes(recipes_data, allergies, dietary_preferences):\n",
        "    recipe_list = []\n",
        "\n",
        "    for recipe in recipes_data:\n",
        "        title = recipe[\"title\"]\n",
        "\n",
        "        # Extract ingredients\n",
        "        ingredients = []\n",
        "        if \"extendedIngredients\" in recipe:\n",
        "            for ingredient in recipe[\"extendedIngredients\"]:\n",
        "                ingredients.append(ingredient[\"name\"])\n",
        "        else:\n",
        "            ingredients = [\"No ingredients provided\"]\n",
        "\n",
        "        # Extract instructions\n",
        "        instructions = recipe.get(\"instructions\", \"No instructions provided\")\n",
        "\n",
        "        # Ensure allergies and dietary preferences are included\n",
        "        recipe_allergies = allergies if allergies else \"Not specified\"\n",
        "        recipe_dietary_preferences = dietary_preferences if dietary_preferences else \"Not specified\"\n",
        "\n",
        "        # Store the recipe data\n",
        "        recipe_list.append({\n",
        "            \"title\": title,\n",
        "            \"ingredients\": ingredients if ingredients else [\"No ingredients provided\"],\n",
        "            \"instructions\": instructions,\n",
        "            \"allergies\": recipe_allergies,\n",
        "            \"dietary_preferences\": recipe_dietary_preferences\n",
        "        })\n",
        "\n",
        "    return recipe_list\n",
        "\n",
        "# Randomize the input parameters\n",
        "ingredient_queries = [\"salad\", \"soup\", \"pasta\", \"dessert\", \"smoothie\"]\n",
        "dietary_preferences_list = [\"vegetarian\", \"vegan\", \"gluten free\", \"paleo\", \"keto\"]\n",
        "allergies_list = [\"gluten\", \"dairy\", \"peanut\", \"soy\", \"egg\", \"tree nut\"]\n",
        "include_ingredients_list = [\"cheese\", \"nuts\", \"tomato\", \"spinach\", \"chicken\", \"carrot\"]\n",
        "exclude_ingredients_list = [\"eggs\", \"milk\", \"wheat\", \"peanut\", \"soy\", \"fish\"]\n",
        "\n",
        "# Randomly select one option from each list\n",
        "ingredient_query = random.choice(ingredient_queries)\n",
        "dietary_preferences = random.choice(dietary_preferences_list)\n",
        "allergies = random.choice(allergies_list)\n",
        "include_ingredients = random.choice(include_ingredients_list)\n",
        "exclude_ingredients = random.choice(exclude_ingredients_list)\n",
        "\n",
        "# Optionally, you can randomize multiple items from each list\n",
        "num_ingredients = 2  # Example: randomly pick 2 ingredients from the list\n",
        "include_ingredients = ','.join(random.sample(include_ingredients_list, num_ingredients))\n",
        "exclude_ingredients = ','.join(random.sample(exclude_ingredients_list, num_ingredients))\n",
        "\n",
        "# Output the randomized inputs (you can remove this print statement if not needed)\n",
        "print(f\"Ingredient Query: {ingredient_query}\")\n",
        "print(f\"Dietary Preferences: {dietary_preferences}\")\n",
        "print(f\"Allergies: {allergies}\")\n",
        "print(f\"Include Ingredients: {include_ingredients}\")\n",
        "print(f\"Exclude Ingredients: {exclude_ingredients}\")\n",
        "\n",
        "# Fetch recipes from Spoonacular API using randomized inputs\n",
        "recipes_data = get_recipes(ingredient_query, dietary_preferences, allergies, include_ingredients, exclude_ingredients, num_recipes=5)\n",
        "\n",
        "# Process the recipes data\n",
        "if recipes_data:\n",
        "    recipes = process_recipes(recipes_data, allergies, dietary_preferences)\n",
        "\n",
        "    # Convert the list to a DataFrame\n",
        "    df = pd.DataFrame(recipes)\n",
        "\n",
        "    # Ensure the directory exists before saving the file\n",
        "    save_path = \"/content/drive/MyDrive/spoonacular_recipes_dataset.csv\"\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "    # Save dataset to a CSV file\n",
        "    df.to_csv(save_path, index=False)\n",
        "    print(f\"Dataset created with {len(df)} recipes.\")\n",
        "else:\n",
        "    print(\"No recipes found or there was an error with the API request.\")\n"
      ],
      "metadata": {
        "id": "1Hegprs690bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#good\n",
        "import http.client\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Spoonacular API and RapidAPI Configuration\n",
        "RAPIDAPI_KEY = \"5bf6609405mshe61b903936f23cep1fd1b6jsn1ecaaf102007\"  # Replace with your RapidAPI key\n",
        "\n",
        "# Function to query Spoonacular API for recipes\n",
        "def get_recipes(diet, intolerances, num_recipes=5):\n",
        "    conn = http.client.HTTPSConnection(\"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\")\n",
        "\n",
        "    headers = {\n",
        "        'x-rapidapi-key': RAPIDAPI_KEY,\n",
        "        'x-rapidapi-host': \"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\"\n",
        "    }\n",
        "\n",
        "    # API endpoint parameters\n",
        "    #url = f\"/recipes/complexSearch?diet={diet}&intolerances={intolerances}fillIngredients=true&number={num_recipes}\"\n",
        "    url = f\"/recipes/complexSearch?diet={diet}&intolerances={intolerances}&instructionsRequired=true&fillIngredients=true&addRecipeInformation=true&number={num_recipes}\"\n",
        "\n",
        "    conn.request(\"GET\", url, headers=headers)\n",
        "    res = conn.getresponse()\n",
        "    data = res.read()\n",
        "\n",
        "    return json.loads(data.decode(\"utf-8\"))\n",
        "\n",
        "# Function to process and store recipe data\n",
        "def process_recipes(recipes_data, allergies, dietary_preferences):\n",
        "    recipe_list = []\n",
        "\n",
        "    for recipe in recipes_data[\"results\"]:\n",
        "        title = recipe[\"title\"]\n",
        "\n",
        "        # Extract ingredients and instructions\n",
        "        ingredients = []\n",
        "        if \"extendedIngredients\" in recipe:\n",
        "            for ingredient in recipe.get(\"extendedIngredients\", []):\n",
        "                ingredients.append(ingredient[\"name\"])\n",
        "\n",
        "        instructions = recipe.get(\"instructions\", \"No instructions provided\")\n",
        "\n",
        "        # Dietary preferences\n",
        "        diet = ', '.join(recipe.get(\"diets\", [])) if \"diets\" in recipe else \"Not specified\"\n",
        "\n",
        "        # Allergies/intolerances\n",
        "        intolerances = ', '.join(recipe.get(\"intolerances\", [])) if \"intolerances\" in recipe else \"Not specified\"\n",
        "\n",
        "        # Store the recipe data\n",
        "        recipe_list.append({\n",
        "            \"title\": title,\n",
        "            \"ingredients\": ingredients if ingredients else [\"No ingredients provided\"],\n",
        "            \"instructions\": instructions,\n",
        "            \"allergies\": intolerances,\n",
        "            \"dietary_preferences\": diet\n",
        "        })\n",
        "\n",
        "    return recipe_list\n",
        "\n",
        "# Define the input parameters\n",
        "ingredient_query = \"salad\"  # Example query\n",
        "dietary_preferences = \"vegetarian\"  # Example dietary preference (can also be \"vegan\", \"gluten free\", etc.)\n",
        "allergies = \"Gluten\"  # Example allergens (e.g., \"gluten\", \"dairy\", \"peanut\")\n",
        "include_ingredients = \"cheese,nuts\"  # Ingredients that must be included\n",
        "exclude_ingredients = \"eggs\"  # Ingredients that must be excluded\n",
        "\n",
        "# Fetch recipes from Spoonacular API\n",
        "recipes_data = get_recipes(dietary_preferences, allergies, num_recipes=5)\n",
        "\n",
        "# Process the recipes data\n",
        "if recipes_data:\n",
        "    recipes = process_recipes(recipes_data, allergies, dietary_preferences)\n",
        "\n",
        "    # Convert the list to a DataFrame\n",
        "    df = pd.DataFrame(recipes)\n",
        "\n",
        "    # Ensure the directory exists before saving the file\n",
        "    save_path = \"/content/drive/MyDrive/spoonacular_recipes_dataset.csv\"\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "    # Save dataset to a CSV file\n",
        "    df.to_csv(save_path, index=False)\n",
        "    print(f\"Dataset created with {len(df)} recipes.\")\n",
        "else:\n",
        "    print(\"No recipes found or there was an error with the API request.\")\n"
      ],
      "metadata": {
        "id": "iTiaeD-8eUcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import http.client\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Spoonacular API and RapidAPI Configuration\n",
        "RAPIDAPI_KEY = \"5bf6609405mshe61b903936f23cep1fd1b6jsn1ecaaf102007\"  # Replace with your RapidAPI key\n",
        "\n",
        "# Function to query Spoonacular API for recipes\n",
        "def get_recipes(diet, intolerances, num_recipes=5):\n",
        "    conn = http.client.HTTPSConnection(\"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\")\n",
        "\n",
        "    headers = {\n",
        "        'x-rapidapi-key': RAPIDAPI_KEY,\n",
        "        'x-rapidapi-host': \"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\"\n",
        "    }\n",
        "\n",
        "    # API endpoint parameters\n",
        "    url = f\"/recipes/complexSearch?diet={diet}&intolerances={intolerances}&instructionsRequired=true&fillIngredients=true&addRecipeInformation=true&number={num_recipes}\"\n",
        "\n",
        "    conn.request(\"GET\", url, headers=headers)\n",
        "    res = conn.getresponse()\n",
        "    data = res.read()\n",
        "\n",
        "    return json.loads(data.decode(\"utf-8\"))\n",
        "\n",
        "# Function to process and store recipe data\n",
        "def process_recipes(recipes_data, allergies, dietary_preferences):\n",
        "    recipe_list = []\n",
        "\n",
        "    for recipe in recipes_data[\"results\"]:\n",
        "        title = recipe[\"title\"]\n",
        "\n",
        "        # Extract ingredients\n",
        "        ingredients = []\n",
        "        if \"extendedIngredients\" in recipe:\n",
        "            for ingredient in recipe.get(\"extendedIngredients\", []):\n",
        "                ingredients.append(ingredient[\"name\"])\n",
        "\n",
        "        # Allergies/intolerances\n",
        "        intolerances = ', '.join(recipe.get(\"intolerances\", [])) if \"intolerances\" in recipe else \"Not specified\"\n",
        "\n",
        "        # Dietary preferences\n",
        "        diet = ', '.join(recipe.get(\"diets\", [])) if \"diets\" in recipe else \"Not specified\"\n",
        "\n",
        "        # Store the recipe data\n",
        "        recipe_list.append({\n",
        "            \"title\": title,\n",
        "            \"ingredients\": ingredients if ingredients else [\"No ingredients provided\"],\n",
        "            \"allergies\": intolerances,\n",
        "            \"dietary_preferences\": diet\n",
        "        })\n",
        "\n",
        "    return recipe_list\n",
        "\n",
        "# Define the input parameters\n",
        "ingredient_query = \"\"  # Example query\n",
        "dietary_preferences = \"\"  # Example dietary preference (can also be \"vegan\", \"gluten free\", etc.)\n",
        "allergies = \"\"  # Example allergens (e.g., \"gluten\", \"dairy\", \"peanut\")\n",
        "include_ingredients = \"\"  # Ingredients that must be included\n",
        "exclude_ingredients = \"\"  # Ingredients that must be excluded\n",
        "\n",
        "# Fetch recipes from Spoonacular API\n",
        "recipes_data = get_recipes(dietary_preferences, allergies, num_recipes=5)\n",
        "\n",
        "# Process the recipes data\n",
        "if recipes_data:\n",
        "    recipes = process_recipes(recipes_data, allergies, dietary_preferences)\n",
        "\n",
        "    # Convert the list to a DataFrame\n",
        "    df = pd.DataFrame(recipes)\n",
        "\n",
        "    # Ensure the directory exists before saving the file\n",
        "    save_path = \"/content/drive/MyDrive/spoonacular_recipes_dataset.csv\"\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "    # Save dataset to a CSV file\n",
        "    df.to_csv(save_path, index=False)\n",
        "    print(f\"Dataset created with {len(df)} recipes.\")\n",
        "else:\n",
        "    print(\"No recipes found or there was an error with the API request.\")\n"
      ],
      "metadata": {
        "id": "yR-xoz_Iisl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import http.client\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Spoonacular API and RapidAPI Configuration\n",
        "RAPIDAPI_KEY = \"5bf6609405mshe61b903936f23cep1fd1b6jsn1ecaaf102007\"  # Replace with your key\n",
        "\n",
        "# Function to fetch random recipes\n",
        "def get_random_recipes(num_recipes=5, tags=\"\"):\n",
        "    conn = http.client.HTTPSConnection(\"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\")\n",
        "    headers = {\n",
        "        'x-rapidapi-key': RAPIDAPI_KEY,\n",
        "        'x-rapidapi-host': \"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\"\n",
        "    }\n",
        "    url = f\"/recipes/random?number={num_recipes}&tags={tags}\"\n",
        "    conn.request(\"GET\", url, headers=headers)\n",
        "    res = conn.getresponse()\n",
        "    data = res.read()\n",
        "    return json.loads(data.decode(\"utf-8\"))\n",
        "\n",
        "# Function to fetch full details for a given recipe ID\n",
        "def get_recipe_details(recipe_id):\n",
        "    conn = http.client.HTTPSConnection(\"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\")\n",
        "    headers = {\n",
        "        'x-rapidapi-key': RAPIDAPI_KEY,\n",
        "        'x-rapidapi-host': \"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\"\n",
        "    }\n",
        "    url = f\"/recipes/{recipe_id}/information?includeNutrition=false\"\n",
        "    conn.request(\"GET\", url, headers=headers)\n",
        "    res = conn.getresponse()\n",
        "    data = res.read()\n",
        "    return json.loads(data.decode(\"utf-8\"))\n",
        "\n",
        "# Function to process recipe data and extract relevant info\n",
        "def process_recipes(recipes_data):\n",
        "    recipe_list = []\n",
        "\n",
        "    for recipe in recipes_data[\"recipes\"]:  # random endpoint returns \"recipes\"\n",
        "        recipe_id = recipe[\"id\"]\n",
        "        details = get_recipe_details(recipe_id)\n",
        "\n",
        "        title = details.get(\"title\", \"No title\")\n",
        "        ingredients = [ing[\"name\"] for ing in details.get(\"extendedIngredients\", [])]\n",
        "\n",
        "        # Allergy/intolerance flags\n",
        "        allergies = []\n",
        "        if details.get(\"glutenFree\"):\n",
        "            allergies.append(\"gluten free\")\n",
        "        if details.get(\"dairyFree\"):\n",
        "            allergies.append(\"dairy free\")\n",
        "        if details.get(\"vegan\"):\n",
        "            allergies.append(\"vegan\")\n",
        "        if details.get(\"vegetarian\"):\n",
        "            allergies.append(\"vegetarian\")\n",
        "\n",
        "        # Diet info\n",
        "        diet = ', '.join(details.get(\"diets\", [])) if \"diets\" in details else \"Not specified\"\n",
        "\n",
        "        recipe_list.append({\n",
        "            \"title\": title,\n",
        "            \"ingredients\": ingredients if ingredients else [\"No ingredients provided\"],\n",
        "            \"allergies\": ', '.join(allergies) if allergies else \"Not specified\",\n",
        "            \"dietary_preferences\": diet\n",
        "        })\n",
        "\n",
        "    return recipe_list\n",
        "\n",
        "# -----------------------\n",
        "# CONFIGURATION\n",
        "# -----------------------\n",
        "num_recipes = 5\n",
        "tags = \"\"  # e.g., \"vegetarian,gluten free\" or leave blank for fully random\n",
        "\n",
        "# Get random recipes\n",
        "recipes_data = get_random_recipes(num_recipes=num_recipes, tags=tags)\n",
        "\n",
        "# Process and store them\n",
        "if recipes_data:\n",
        "    recipes = process_recipes(recipes_data)\n",
        "    df = pd.DataFrame(recipes)\n",
        "\n",
        "    # Save to Google Drive or local path\n",
        "    save_path = \"/content/drive/MyDrive/spoonacular_recipes_dataset.csv\"\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "    df.to_csv(save_path, index=False)\n",
        "    print(f\"✅ Dataset created with {len(df)} recipes. Saved to: {save_path}\")\n",
        "else:\n",
        "    print(\"❌ No recipes found or API request failed.\")\n"
      ],
      "metadata": {
        "id": "TtWhGNAMnsw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import http.client\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Spoonacular API and RapidAPI Configuration\n",
        "RAPIDAPI_KEY = \"5bf6609405mshe61b903936f23cep1fd1b6jsn1ecaaf102007\"\n",
        "\n",
        "# Function to fetch random recipes\n",
        "def get_random_recipes(num_recipes=10, tags=\"\"):\n",
        "    conn = http.client.HTTPSConnection(\"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\")\n",
        "    headers = {\n",
        "        'x-rapidapi-key': RAPIDAPI_KEY,\n",
        "        'x-rapidapi-host': \"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\"\n",
        "    }\n",
        "    url = f\"/recipes/random?number={num_recipes}&tags={tags}\"\n",
        "    conn.request(\"GET\", url, headers=headers)\n",
        "    res = conn.getresponse()\n",
        "    data = res.read()\n",
        "    return json.loads(data.decode(\"utf-8\"))\n",
        "\n",
        "# Function to fetch detailed info for one recipe\n",
        "def get_recipe_details(recipe_id):\n",
        "    conn = http.client.HTTPSConnection(\"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\")\n",
        "    headers = {\n",
        "        'x-rapidapi-key': RAPIDAPI_KEY,\n",
        "        'x-rapidapi-host': \"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\"\n",
        "    }\n",
        "    url = f\"/recipes/{recipe_id}/information?includeNutrition=false\"\n",
        "    conn.request(\"GET\", url, headers=headers)\n",
        "    res = conn.getresponse()\n",
        "    data = res.read()\n",
        "    return json.loads(data.decode(\"utf-8\"))\n",
        "\n",
        "# Process a batch of recipes\n",
        "def process_recipes(recipes_data):\n",
        "    recipe_list = []\n",
        "\n",
        "    for recipe in recipes_data[\"recipes\"]:\n",
        "        recipe_id = recipe[\"id\"]\n",
        "        details = get_recipe_details(recipe_id)\n",
        "        time.sleep(0.5)  # Prevent throttling\n",
        "\n",
        "        title = details.get(\"title\", \"No title\")\n",
        "        ingredients = [ing[\"name\"] for ing in details.get(\"extendedIngredients\", [])]\n",
        "\n",
        "        allergies = []\n",
        "        if details.get(\"glutenFree\"):\n",
        "            allergies.append(\"gluten free\")\n",
        "        if details.get(\"dairyFree\"):\n",
        "            allergies.append(\"dairy free\")\n",
        "\n",
        "        diet = ', '.join(details.get(\"diets\", [])) if \"diets\" in details else \"Not specified\"\n",
        "\n",
        "        recipe_list.append({\n",
        "            \"title\": title,\n",
        "            \"ingredients\": ingredients if ingredients else [\"No ingredients provided\"],\n",
        "            \"allergies\": ', '.join(allergies) if allergies else \"Not specified\",\n",
        "            \"dietary_preferences\": diet\n",
        "        })\n",
        "\n",
        "    return recipe_list\n",
        "\n",
        "# -----------------------\n",
        "# CONFIGURATION\n",
        "# -----------------------\n",
        "total_recipes = 1000\n",
        "batch_size = 10\n",
        "save_path = \"/content/drive/MyDrive/spoonacular_recipes_dataset.csv\"\n",
        "tags = \"\"\n",
        "\n",
        "# Ensure save path exists\n",
        "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "# Check if we're resuming\n",
        "if os.path.exists(save_path):\n",
        "    existing_df = pd.read_csv(save_path)\n",
        "    already_fetched = len(existing_df)\n",
        "    print(f\"🔁 Resuming: {already_fetched} recipes already fetched.\")\n",
        "else:\n",
        "    existing_df = pd.DataFrame()\n",
        "    already_fetched = 0\n",
        "\n",
        "# Start fetching remaining recipes\n",
        "for batch_num in range(already_fetched // batch_size, total_recipes // batch_size):\n",
        "    print(f\"📦 Fetching batch {batch_num + 1} of {total_recipes // batch_size}\")\n",
        "    try:\n",
        "        recipes_data = get_random_recipes(num_recipes=batch_size, tags=tags)\n",
        "        if recipes_data:\n",
        "            processed = process_recipes(recipes_data)\n",
        "            batch_df = pd.DataFrame(processed)\n",
        "            batch_df.to_csv(save_path, mode='a', index=False, header=not os.path.exists(save_path) and batch_num == 0)\n",
        "            print(f\"✅ Batch {batch_num + 1} saved.\")\n",
        "        else:\n",
        "            print(\"⚠️ Failed to fetch a batch. Skipping...\")\n",
        "        time.sleep(1)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error in batch {batch_num + 1}: {e}\")\n",
        "        break\n",
        "\n",
        "print(f\"\\n🎉 Completed. Check {save_path} for your full dataset.\")\n"
      ],
      "metadata": {
        "id": "wR_X_rU7oLmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import http.client\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "# Spoonacular API and RapidAPI Configuration\n",
        "RAPIDAPI_KEY = \"5bf6609405mshe61b903936f23cep1fd1b6jsn1ecaaf102007\"\n",
        "\n",
        "# Function to fetch random recipes\n",
        "def get_random_recipes(num_recipes=10, tags=\"\"):\n",
        "    conn = http.client.HTTPSConnection(\"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\")\n",
        "    headers = {\n",
        "        'x-rapidapi-key': RAPIDAPI_KEY,\n",
        "        'x-rapidapi-host': \"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\"\n",
        "    }\n",
        "    url = f\"/recipes/random?number={num_recipes}&tags={tags}\"\n",
        "    conn.request(\"GET\", url, headers=headers)\n",
        "    res = conn.getresponse()\n",
        "    data = res.read()\n",
        "    return json.loads(data.decode(\"utf-8\"))\n",
        "\n",
        "# Function to fetch detailed info for one recipe\n",
        "def get_recipe_details(recipe_id):\n",
        "    conn = http.client.HTTPSConnection(\"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\")\n",
        "    headers = {\n",
        "        'x-rapidapi-key': RAPIDAPI_KEY,\n",
        "        'x-rapidapi-host': \"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\"\n",
        "    }\n",
        "    url = f\"/recipes/{recipe_id}/information?includeNutrition=false\"\n",
        "    conn.request(\"GET\", url, headers=headers)\n",
        "    res = conn.getresponse()\n",
        "    data = res.read()\n",
        "    return json.loads(data.decode(\"utf-8\"))\n",
        "\n",
        "# Process a batch of recipes\n",
        "def process_recipes(recipes_data):\n",
        "    recipe_list = []\n",
        "\n",
        "    for recipe in recipes_data[\"recipes\"]:\n",
        "        recipe_id = recipe[\"id\"]\n",
        "        details = get_recipe_details(recipe_id)\n",
        "        time.sleep(0.5)\n",
        "\n",
        "        title = details.get(\"title\", \"No title\")\n",
        "        ingredients = [ing[\"name\"] for ing in details.get(\"extendedIngredients\", [])]\n",
        "\n",
        "        allergies = []\n",
        "        if details.get(\"glutenFree\"):\n",
        "            allergies.append(\"gluten free\")\n",
        "        if details.get(\"dairyFree\"):\n",
        "            allergies.append(\"dairy free\")\n",
        "\n",
        "        diet = ', '.join(details.get(\"diets\", [])) if \"diets\" in details else \"Not specified\"\n",
        "\n",
        "        recipe_list.append({\n",
        "            \"title\": title,\n",
        "            \"ingredients\": ingredients if ingredients else [\"No ingredients provided\"],\n",
        "            \"allergies\": ', '.join(allergies) if allergies else \"Not specified\",\n",
        "            \"dietary_preferences\": diet\n",
        "        })\n",
        "\n",
        "    return recipe_list\n",
        "\n",
        "# -----------------------\n",
        "# CONFIGURATION\n",
        "# -----------------------\n",
        "total_recipes = 1000\n",
        "batch_size = 10\n",
        "save_path = \"/content/drive/MyDrive/spoonacular_recipes_dataset.csv\"\n",
        "tags = \"\"\n",
        "\n",
        "# Ensure path exists\n",
        "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "# Delete old file if exists\n",
        "if os.path.exists(save_path):\n",
        "    os.remove(save_path)\n",
        "    print(\"🗑️ Old dataset deleted.\")\n",
        "\n",
        "# Start collection\n",
        "for batch_num in range(total_recipes // batch_size):\n",
        "    print(f\"📦 Fetching batch {batch_num + 1} of {total_recipes // batch_size}\")\n",
        "    try:\n",
        "        recipes_data = get_random_recipes(num_recipes=batch_size, tags=tags)\n",
        "        if recipes_data:\n",
        "            processed = process_recipes(recipes_data)\n",
        "            batch_df = pd.DataFrame(processed)\n",
        "\n",
        "            if batch_num == 0:\n",
        "                batch_df.to_csv(save_path, mode='w', index=False, header=True)\n",
        "            else:\n",
        "                batch_df.to_csv(save_path, mode='a', index=False, header=False)\n",
        "\n",
        "            print(f\"✅ Batch {batch_num + 1} saved.\")\n",
        "        else:\n",
        "            print(\"⚠️ Empty batch received.\")\n",
        "        time.sleep(1)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error in batch {batch_num + 1}: {e}\")\n",
        "        break\n",
        "\n",
        "# Final file check\n",
        "if Path(save_path).exists():\n",
        "    file_size = Path(save_path).stat().st_size / 1024\n",
        "    print(f\"\\n🎉 Done. File saved to: {save_path}\")\n",
        "    print(f\"📁 File size: {file_size:.1f} KB\")\n",
        "else:\n",
        "    print(\"❌ File was not saved.\")\n"
      ],
      "metadata": {
        "id": "GrRxJaWpGb4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0E3xQvvjF2Dz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# includes instructions\n",
        "import http.client\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "# ✅ STEP 2: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Spoonacular API and RapidAPI Configuration\n",
        "RAPIDAPI_KEY = \"5bf6609405mshe61b903936f23cep1fd1b6jsn1ecaaf102007\"\n",
        "\n",
        "# Function to fetch random recipes\n",
        "def get_random_recipes(num_recipes=10, tags=\"\"):\n",
        "    conn = http.client.HTTPSConnection(\"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\")\n",
        "    headers = {\n",
        "        'x-rapidapi-key': RAPIDAPI_KEY,\n",
        "        'x-rapidapi-host': \"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\"\n",
        "    }\n",
        "    url = f\"/recipes/random?number={num_recipes}&tags={tags}\"\n",
        "    conn.request(\"GET\", url, headers=headers)\n",
        "    res = conn.getresponse()\n",
        "    data = res.read()\n",
        "    return json.loads(data.decode(\"utf-8\"))\n",
        "\n",
        "# Function to fetch detailed info for one recipe\n",
        "def get_recipe_details(recipe_id):\n",
        "    conn = http.client.HTTPSConnection(\"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\")\n",
        "    headers = {\n",
        "        'x-rapidapi-key': RAPIDAPI_KEY,\n",
        "        'x-rapidapi-host': \"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\"\n",
        "    }\n",
        "    url = f\"/recipes/{recipe_id}/information?includeNutrition=false\"\n",
        "    conn.request(\"GET\", url, headers=headers)\n",
        "    res = conn.getresponse()\n",
        "    data = res.read()\n",
        "    return json.loads(data.decode(\"utf-8\"))\n",
        "\n",
        "# Process a batch of recipes\n",
        "def process_recipes(recipes_data):\n",
        "    recipe_list = []\n",
        "\n",
        "    for recipe in recipes_data[\"recipes\"]:\n",
        "        recipe_id = recipe[\"id\"]\n",
        "        details = get_recipe_details(recipe_id)\n",
        "        time.sleep(0.5)\n",
        "\n",
        "        title = details.get(\"title\", \"No title\")\n",
        "        ingredients = [ing[\"name\"] for ing in details.get(\"extendedIngredients\", [])]\n",
        "\n",
        "        # Extract instructions (if available)\n",
        "        instructions = []\n",
        "        for section in details.get(\"analyzedInstructions\", []):\n",
        "            for step in section.get(\"steps\", []):\n",
        "                instructions.append(step.get(\"step\"))\n",
        "\n",
        "        instructions_text = \"\\n\".join(instructions).strip() if instructions else \"No instructions provided.\"\n",
        "\n",
        "        allergies = []\n",
        "        if details.get(\"glutenFree\"):\n",
        "            allergies.append(\"gluten free\")\n",
        "        if details.get(\"dairyFree\"):\n",
        "            allergies.append(\"dairy free\")\n",
        "\n",
        "        diet = ', '.join(details.get(\"diets\", [])) if \"diets\" in details else \"Not specified\"\n",
        "\n",
        "        recipe_list.append({\n",
        "            \"title\": title,\n",
        "            \"ingredients\": ingredients if ingredients else [\"No ingredients provided\"],\n",
        "            \"instructions\": instructions_text,\n",
        "            \"allergies\": ', '.join(allergies) if allergies else \"Not specified\",\n",
        "            \"dietary_preferences\": diet\n",
        "        })\n",
        "\n",
        "    return recipe_list\n",
        "\n",
        "# -----------------------\n",
        "# CONFIGURATION\n",
        "# -----------------------\n",
        "total_recipes = 1500\n",
        "batch_size = 10\n",
        "save_path = \"/content/drive/MyDrive/spoonacular_recipes_dataset1.csv\"\n",
        "tags = \"\"\n",
        "\n",
        "# Ensure path exists\n",
        "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "# Delete old file if exists\n",
        "if os.path.exists(save_path):\n",
        "    os.remove(save_path)\n",
        "    print(\"🗑️ Old dataset deleted.\")\n",
        "\n",
        "# Start collection\n",
        "for batch_num in range(total_recipes // batch_size):\n",
        "    print(f\"📦 Fetching batch {batch_num + 1} of {total_recipes // batch_size}\")\n",
        "    try:\n",
        "        recipes_data = get_random_recipes(num_recipes=batch_size, tags=tags)\n",
        "        if recipes_data:\n",
        "            processed = process_recipes(recipes_data)\n",
        "            batch_df = pd.DataFrame(processed)\n",
        "\n",
        "            if batch_num == 0:\n",
        "                batch_df.to_csv(save_path, mode='w', index=False, header=True)\n",
        "            else:\n",
        "                batch_df.to_csv(save_path, mode='a', index=False, header=False)\n",
        "\n",
        "            print(f\"✅ Batch {batch_num + 1} saved.\")\n",
        "        else:\n",
        "            print(\"⚠️ Empty batch received.\")\n",
        "        time.sleep(1)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error in batch {batch_num + 1}: {e}\")\n",
        "        break\n",
        "\n",
        "# Final file check\n",
        "if Path(save_path).exists():\n",
        "    file_size = Path(save_path).stat().st_size / 1024\n",
        "    print(f\"\\n🎉 Done. File saved to: {save_path}\")\n",
        "    print(f\"📁 File size: {file_size:.1f} KB\")\n",
        "else:\n",
        "    print(\"❌ File was not saved.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Bkby3DQ6Omn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import http.client\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "# Spoonacular API and RapidAPI Configuration\n",
        "RAPIDAPI_KEY = \"5bf6609405mshe61b903936f23cep1fd1b6jsn1ecaaf102007\"\n",
        "\n",
        "# Function to fetch random recipes\n",
        "def get_random_recipes(num_recipes=10, tags=\"\"):\n",
        "    conn = http.client.HTTPSConnection(\"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\")\n",
        "    headers = {\n",
        "        'x-rapidapi-key': RAPIDAPI_KEY,\n",
        "        'x-rapidapi-host': \"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\"\n",
        "    }\n",
        "    url = f\"/recipes/random?number={num_recipes}&tags={tags}\"\n",
        "    conn.request(\"GET\", url, headers=headers)\n",
        "    res = conn.getresponse()\n",
        "    data = res.read()\n",
        "    return json.loads(data.decode(\"utf-8\"))\n",
        "\n",
        "# Function to fetch detailed info for one recipe\n",
        "def get_recipe_details(recipe_id):\n",
        "    conn = http.client.HTTPSConnection(\"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\")\n",
        "    headers = {\n",
        "        'x-rapidapi-key': RAPIDAPI_KEY,\n",
        "        'x-rapidapi-host': \"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\"\n",
        "    }\n",
        "    url = f\"/recipes/{recipe_id}/information?includeNutrition=false\"\n",
        "    conn.request(\"GET\", url, headers=headers)\n",
        "    res = conn.getresponse()\n",
        "    data = res.read()\n",
        "    return json.loads(data.decode(\"utf-8\"))\n",
        "\n",
        "# Function to clean instructions\n",
        "def clean_instructions(text):\n",
        "    if not text:\n",
        "        return \"Instructions not available.\"\n",
        "    cutoff_phrases = [\n",
        "        \"Note:\", \"Nutritional\", \"Source:\", \"Enjoy!\",\n",
        "        \"provided by\", \"Food Network\", \"FN chefs\", \"do not include personal\"\n",
        "    ]\n",
        "    for phrase in cutoff_phrases:\n",
        "        idx = text.lower().find(phrase.lower())\n",
        "        if idx != -1:\n",
        "            return text[:idx].strip()\n",
        "    return text.strip()\n",
        "\n",
        "# Process a batch of recipes\n",
        "def process_recipes(recipes_data):\n",
        "    recipe_list = []\n",
        "\n",
        "    for recipe in recipes_data[\"recipes\"]:\n",
        "        recipe_id = recipe[\"id\"]\n",
        "        details = get_recipe_details(recipe_id)\n",
        "        time.sleep(0.5)\n",
        "\n",
        "        title = details.get(\"title\", \"No title\")\n",
        "        ingredients = [ing[\"name\"] for ing in details.get(\"extendedIngredients\", [])]\n",
        "\n",
        "        # Extract and clean instructions\n",
        "        raw_steps = []\n",
        "        for section in details.get(\"analyzedInstructions\", []):\n",
        "            for step in section.get(\"steps\", []):\n",
        "                raw_steps.append(step.get(\"step\"))\n",
        "\n",
        "        full_instructions = \"\\n\".join(raw_steps).strip()\n",
        "        cleaned_instructions = clean_instructions(full_instructions)\n",
        "\n",
        "        allergies = []\n",
        "        if details.get(\"glutenFree\"):\n",
        "            allergies.append(\"gluten free\")\n",
        "        if details.get(\"dairyFree\"):\n",
        "            allergies.append(\"dairy free\")\n",
        "\n",
        "        diet = ', '.join(details.get(\"diets\", [])) if \"diets\" in details else \"Not specified\"\n",
        "\n",
        "        recipe_list.append({\n",
        "            \"title\": title,\n",
        "            \"ingredients\": ingredients if ingredients else [\"No ingredients provided\"],\n",
        "            \"instructions\": cleaned_instructions,\n",
        "            \"allergies\": ', '.join(allergies) if allergies else \"Not specified\",\n",
        "            \"dietary_preferences\": diet\n",
        "        })\n",
        "\n",
        "    return recipe_list\n",
        "\n",
        "# -----------------------\n",
        "# CONFIGURATION\n",
        "# -----------------------\n",
        "total_recipes = 1000\n",
        "batch_size = 10\n",
        "save_path = \"/content/drive/MyDrive/spoonacular_recipes_dataset2.csv\"\n",
        "tags = \"\"\n",
        "\n",
        "# Ensure path exists\n",
        "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "# Delete old file if exists\n",
        "if os.path.exists(save_path):\n",
        "    os.remove(save_path)\n",
        "    print(\"🗑️ Old dataset deleted.\")\n",
        "\n",
        "# Start collection\n",
        "for batch_num in range(total_recipes // batch_size):\n",
        "    print(f\"📦 Fetching batch {batch_num + 1} of {total_recipes // batch_size}\")\n",
        "    try:\n",
        "        recipes_data = get_random_recipes(num_recipes=batch_size, tags=tags)\n",
        "        if recipes_data:\n",
        "            processed = process_recipes(recipes_data)\n",
        "            batch_df = pd.DataFrame(processed)\n",
        "\n",
        "            if batch_num == 0:\n",
        "                batch_df.to_csv(save_path, mode='w', index=False, header=True)\n",
        "            else:\n",
        "                batch_df.to_csv(save_path, mode='a', index=False, header=False)\n",
        "\n",
        "            print(f\"✅ Batch {batch_num + 1} saved.\")\n",
        "        else:\n",
        "            print(\"⚠️ Empty batch received.\")\n",
        "        time.sleep(1)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error in batch {batch_num + 1}: {e}\")\n",
        "        break\n",
        "\n",
        "# Final file check\n",
        "if Path(save_path).exists():\n",
        "    file_size = Path(save_path).stat().st_size / 1024\n",
        "    print(f\"\\n🎉 Done. File saved to: {save_path}\")\n",
        "    print(f\"📁 File size: {file_size:.1f} KB\")\n",
        "else:\n",
        "    print(\"❌ File was not saved.\")\n"
      ],
      "metadata": {
        "id": "Kq2RInLRkSI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 1: Install necessary packages\n",
        "!pip install -q unsloth datasets bitsandbytes accelerate peft transformers\n",
        "\n",
        "# ✅ STEP 2: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ✅ STEP 3: Load model with Unsloth\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "adapter_path = \"/content/drive/MyDrive/deepseek-7b-recipe-lora2\"\n",
        "model_name = \"deepseek-ai/deepseek-llm-7b-base\"\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=model_name,\n",
        "    max_seq_length=1024,\n",
        "    dtype=torch.bfloat16,\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# ✅ STEP 4: Load LoRA adapters\n",
        "model.load_adapter(adapter_path)\n",
        "\n",
        "# ✅ STEP 5: Load and format dataset\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "import ast\n",
        "\n",
        "# Load your cleaned CSV with instructions\n",
        "df = pd.read_csv('/content/drive/MyDrive/spoonacular_recipes_dataset2.csv')\n",
        "\n",
        "# ✅ Safely format response column\n",
        "def format_response(row):\n",
        "    try:\n",
        "        ingredients = ast.literal_eval(row['ingredients']) if isinstance(row['ingredients'], str) else row['ingredients']\n",
        "        if not isinstance(ingredients, list):\n",
        "            ingredients = [\"ingredient1\", \"ingredient2\"]\n",
        "    except:\n",
        "        ingredients = [\"ingredient1\", \"ingredient2\"]\n",
        "\n",
        "    title = row['title'] if isinstance(row['title'], str) else \"Untitled Recipe\"\n",
        "    instructions = row['instructions'] if isinstance(row['instructions'], str) else \"Instructions not available.\"\n",
        "\n",
        "    return (\n",
        "        f\"{title}\\n\\n\"\n",
        "        f\"Ingredients:\\n\" +\n",
        "        \"\\n\".join(f\"- {i}\" for i in ingredients) +\n",
        "        \"\\n\\nInstructions:\\n\" + instructions\n",
        "    )\n",
        "\n",
        "df['response'] = df.apply(format_response, axis=1)\n",
        "\n",
        "# ✅ Format the prompt with proper fallbacks\n",
        "df['prompt'] = df.apply(\n",
        "    lambda x: f\"<|user|> Generate a recipe using ONLY the following ingredients: {', '.join(ast.literal_eval(x['ingredients'])) if isinstance(x['ingredients'], str) else x['ingredients']}. \"\n",
        "              f\"Do not include the following allergens: {x['allergies'] if isinstance(x['allergies'], str) else 'none'}. \"\n",
        "              f\"Ensure the recipe follows these dietary preferences: {x['dietary_preferences'] if isinstance(x['dietary_preferences'], str) else 'none'}. \"\n",
        "              f\"Include title, ingredients, and detailed step-by-step instructions. <|assistant|>\",\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# ✅ Combine for model input\n",
        "df['text'] = df['prompt'] + \"\\n\" + df['response']\n",
        "\n",
        "# ✅ STEP 6: Tokenize\n",
        "max_length = 1024\n",
        "\n",
        "def tokenize(example):\n",
        "    model_inputs = tokenizer(\n",
        "        example[\"text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=max_length\n",
        "    )\n",
        "    model_inputs[\"labels\"] = [\n",
        "        [-100 if token == tokenizer.pad_token_id else token for token in input_ids]\n",
        "        for input_ids in model_inputs[\"input_ids\"]\n",
        "    ]\n",
        "    return model_inputs\n",
        "\n",
        "dataset = Dataset.from_pandas(df[['text']])\n",
        "dataset = dataset.train_test_split(test_size=0.05)\n",
        "\n",
        "tokenized_train = dataset[\"train\"].map(tokenize, batched=True, remove_columns=[\"text\"])\n",
        "tokenized_eval = dataset[\"test\"].map(tokenize, batched=True, remove_columns=[\"text\"])\n",
        "\n",
        "# ✅ STEP 7: Trainer setup\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/deepseek-7b-recipe-lora2-continued2\",\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=2,\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=250,\n",
        "    save_total_limit=2,\n",
        "    bf16=True,\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    warmup_steps=5,\n",
        "    weight_decay=0.01,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    learning_rate=2e-4,\n",
        "    report_to=\"none\",\n",
        "    remove_unused_columns=False\n",
        ")\n",
        "\n",
        "model.enable_input_require_grads()\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_eval,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# ✅ STEP 8: Train the model\n",
        "trainer.train()\n",
        "\n",
        "# ✅ STEP 9: Save\n",
        "model.save_pretrained(\"/content/drive/MyDrive/deepseek-7b-recipe-lora2-continued2\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/deepseek-7b-recipe-lora2-continued2\")\n",
        "\n",
        "print(\"✅ Fine-tuning complete. Model saved.\")\n"
      ],
      "metadata": {
        "id": "EuKcr1v8tm-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Install required packages\n",
        "!pip install -q unsloth transformers bitsandbytes accelerate peft\n",
        "\n",
        "# ✅ Imports and Mount Google Drive\n",
        "import torch\n",
        "from unsloth import FastLanguageModel\n",
        "from transformers import GenerationConfig\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ✅ Load the fine-tuned model\n",
        "model_path = \"/content/drive/MyDrive/deepseek-7b-recipe-lora2-continued2\"\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=model_path,\n",
        "    max_seq_length=1024,\n",
        "    dtype=torch.bfloat16,\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# ✅ Build prompt dynamically\n",
        "def build_prompt(ingredients, allergies=\"\", diet=\"\"):\n",
        "    base = f\"<|user|> Generate a recipe using ONLY the following ingredients: {', '.join(ingredients)}. \"\n",
        "    if allergies:\n",
        "        base += f\"Do not include the following allergens: {allergies}. \"\n",
        "    if diet:\n",
        "        base += f\"Ensure the recipe follows these dietary preferences: {diet}. \"\n",
        "    base += \"Include title, ingredients, and detailed step-by-step instructions. <|assistant|>\"\n",
        "    return base\n",
        "\n",
        "# ✅ Generate a recipe with stronger controls\n",
        "def generate_recipe(prompt, max_tokens=350):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_tokens,\n",
        "            do_sample=True,\n",
        "            temperature=0.5,        # More conservative\n",
        "            top_p=0.8,              # Less diversity\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            pad_token_id=tokenizer.pad_token_id\n",
        "        )\n",
        "\n",
        "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "    # ✅ Remove repeated hallucination via manual cutoff\n",
        "    response = decoded[len(prompt):].strip()\n",
        "    response = response.split(\"<|endoftext|>\")[0].strip()  # stop if hallucinated\n",
        "    response = response.split(\"Ingredients:\")[0].strip() + \"\\nIngredients:\\n\" + response.split(\"Ingredients:\")[-1].split(\"Instructions:\")[0].strip() + \"\\n\\nInstructions:\\n\" + response.split(\"Instructions:\")[-1].strip()\n",
        "\n",
        "    return response\n",
        "\n",
        "# ✅ Run test cases\n",
        "test_cases = [\n",
        "    {\n",
        "        \"ingredients\": [\"chickpeas\", \"olive oil\", \"lemon\", \"garlic\"],\n",
        "        \"allergies\": \"dairy, gluten\",\n",
        "        \"diet\": \"vegan\"\n",
        "    },\n",
        "    {\n",
        "        \"ingredients\": [\"quinoa\", \"black beans\", \"bell pepper\", \"avocado\"],\n",
        "        \"allergies\": \"\",\n",
        "        \"diet\": \"vegetarian\"\n",
        "    },\n",
        "    {\n",
        "        \"ingredients\": [\"salmon\", \"asparagus\", \"olive oil\", \"lemon\"],\n",
        "        \"allergies\": \"\",\n",
        "        \"diet\": \"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "for i, case in enumerate(test_cases, 1):\n",
        "    print(f\"\\n🔹 Test Case {i}\")\n",
        "    prompt = build_prompt(case[\"ingredients\"], case[\"allergies\"], case[\"diet\"])\n",
        "    output = generate_recipe(prompt)\n",
        "    print(output)\n",
        "# might be the best option"
      ],
      "metadata": {
        "id": "-_nN3sozfO9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import http.client\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "RAPIDAPI_KEY = \"5bf6609405mshe61b903936f23cep1fd1b6jsn1ecaaf102007\"\n",
        "\n",
        "def get_random_recipes(num_recipes=10, tags=\"\"):\n",
        "    conn = http.client.HTTPSConnection(\"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\")\n",
        "    headers = {\n",
        "        'x-rapidapi-key': RAPIDAPI_KEY,\n",
        "        'x-rapidapi-host': \"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\"\n",
        "    }\n",
        "    url = f\"/recipes/random?number={num_recipes}&tags={tags}\"\n",
        "    conn.request(\"GET\", url, headers=headers)\n",
        "    return json.loads(conn.getresponse().read().decode(\"utf-8\"))\n",
        "\n",
        "def get_recipe_details(recipe_id):\n",
        "    conn = http.client.HTTPSConnection(\"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\")\n",
        "    headers = {\n",
        "        'x-rapidapi-key': RAPIDAPI_KEY,\n",
        "        'x-rapidapi-host': \"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\"\n",
        "    }\n",
        "    url = f\"/recipes/{recipe_id}/information?includeNutrition=false\"\n",
        "    conn.request(\"GET\", url, headers=headers)\n",
        "    return json.loads(conn.getresponse().read().decode(\"utf-8\"))\n",
        "\n",
        "def clean_instructions(text):\n",
        "    if not text or not isinstance(text, str): return \"\"\n",
        "    cutoff_phrases = [\"fn chefs\", \"provided by\", \"visit\", \"copyright\", \"donate\", \"national ms society\", \"follow me\"]\n",
        "    for phrase in cutoff_phrases:\n",
        "        idx = text.lower().find(phrase)\n",
        "        if idx != -1:\n",
        "            text = text[:idx]\n",
        "    return re.sub(r\"\\n{2,}\", \"\\n\", text.strip())\n",
        "\n",
        "def process_recipes(recipes_data):\n",
        "    recipe_list = []\n",
        "    for recipe in recipes_data[\"recipes\"]:\n",
        "        recipe_id = recipe[\"id\"]\n",
        "        details = get_recipe_details(recipe_id)\n",
        "        time.sleep(0.5)\n",
        "\n",
        "        title = details.get(\"title\", \"Untitled\")\n",
        "        ingredients = [i[\"name\"] for i in details.get(\"extendedIngredients\", [])]\n",
        "        raw_steps = [step[\"step\"] for instr in details.get(\"analyzedInstructions\", []) for step in instr.get(\"steps\", [])]\n",
        "        instructions = clean_instructions(\"\\n\".join(raw_steps))\n",
        "\n",
        "        if len(instructions.split()) < 20: continue\n",
        "\n",
        "        allergies = []\n",
        "        if details.get(\"glutenFree\"): allergies.append(\"gluten free\")\n",
        "        if details.get(\"dairyFree\"): allergies.append(\"dairy free\")\n",
        "        diet = ', '.join(details.get(\"diets\", [])) or \"Not specified\"\n",
        "\n",
        "        recipe_list.append({\n",
        "            \"title\": title,\n",
        "            \"ingredients\": ingredients if ingredients else [\"No ingredients provided\"],\n",
        "            \"instructions\": instructions,\n",
        "            \"allergies\": ', '.join(allergies) if allergies else \"Not specified\",\n",
        "            \"dietary_preferences\": diet\n",
        "        })\n",
        "\n",
        "    return recipe_list\n",
        "\n",
        "# CONFIG\n",
        "total_recipes = 2000\n",
        "batch_size = 10\n",
        "save_path = \"/content/drive/MyDrive/spoonacular_recipes_dataset_v3.csv\"\n",
        "\n",
        "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "if os.path.exists(save_path): os.remove(save_path)\n",
        "\n",
        "for batch_num in range(total_recipes // batch_size):\n",
        "    print(f\"📦 Batch {batch_num + 1}\")\n",
        "    try:\n",
        "        data = get_random_recipes(batch_size)\n",
        "        processed = process_recipes(data)\n",
        "        if processed:\n",
        "            df = pd.DataFrame(processed)\n",
        "            df.to_csv(save_path, mode='a', index=False, header=not os.path.exists(save_path))\n",
        "            print(f\"✅ Saved {len(df)} entries.\")\n",
        "        time.sleep(1)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error in batch {batch_num + 1}: {e}\")\n",
        "        break\n",
        "\n",
        "print(f\"\\n🎉 Dataset complete. Saved to: {save_path}\")\n"
      ],
      "metadata": {
        "id": "nc_UWsyCIMhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q unsloth datasets bitsandbytes accelerate peft transformers\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "import ast\n",
        "\n",
        "# ✅ Load base model + adapter (lora2)\n",
        "adapter_path = \"/content/drive/MyDrive/deepseek-7b-recipe-lora2\"\n",
        "model_name = \"deepseek-ai/deepseek-llm-7b-base\"\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=model_name,\n",
        "    max_seq_length=1024,\n",
        "    dtype=torch.bfloat16,\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "model.load_adapter(adapter_path)\n",
        "\n",
        "# ✅ Load v3 dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/spoonacular_recipes_dataset_v3.csv\")\n",
        "\n",
        "def format_response(row):\n",
        "    try:\n",
        "        ingredients = ast.literal_eval(row['ingredients']) if isinstance(row['ingredients'], str) else row['ingredients']\n",
        "    except:\n",
        "        ingredients = [\"ingredient1\", \"ingredient2\"]\n",
        "    title = row.get('title', 'Untitled Recipe')\n",
        "    instructions = row.get('instructions', 'Instructions not available.')\n",
        "    return f\"{title}\\n\\nIngredients:\\n\" + \"\\n\".join(f\"- {i}\" for i in ingredients) + \"\\n\\nInstructions:\\n\" + instructions\n",
        "\n",
        "df['response'] = df.apply(format_response, axis=1)\n",
        "df['prompt'] = df.apply(\n",
        "    lambda x: f\"<|user|> Generate a recipe using ONLY the following ingredients: {', '.join(ast.literal_eval(x['ingredients'])) if isinstance(x['ingredients'], str) else x['ingredients']}. \" +\n",
        "              (f\"Do not include the following allergens: {x['allergies']}. \" if isinstance(x['allergies'], str) and x['allergies'] != \"Not specified\" else \"\") +\n",
        "              (f\"Ensure the recipe follows these dietary preferences: {x['dietary_preferences']}. \" if isinstance(x['dietary_preferences'], str) and x['dietary_preferences'] != \"Not specified\" else \"\") +\n",
        "              \"Include title, ingredients, and detailed step-by-step instructions. <|assistant|>\",\n",
        "    axis=1\n",
        ")\n",
        "df[\"text\"] = df[\"prompt\"] + \"\\n\" + df[\"response\"] + \"\\n<|endoftext|>\"\n",
        "\n",
        "# ✅ Tokenization\n",
        "max_length = 1024\n",
        "def tokenize(example):\n",
        "    tokens = tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=max_length)\n",
        "    tokens[\"labels\"] = [[-100 if token == tokenizer.pad_token_id else token for token in ids] for ids in tokens[\"input_ids\"]]\n",
        "    return tokens\n",
        "\n",
        "dataset = Dataset.from_pandas(df[[\"text\"]]).train_test_split(test_size=0.05)\n",
        "tokenized_train = dataset[\"train\"].map(tokenize, batched=True, remove_columns=[\"text\"])\n",
        "tokenized_eval = dataset[\"test\"].map(tokenize, batched=True, remove_columns=[\"text\"])\n",
        "\n",
        "# ✅ Training setup\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/deepseek-7b-recipe-lora2-v3\",\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=1,\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=250,\n",
        "    save_total_limit=2,\n",
        "    bf16=True,\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    warmup_steps=5,\n",
        "    weight_decay=0.01,\n",
        "    learning_rate=2e-4,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    report_to=\"none\",\n",
        "    remove_unused_columns=False\n",
        ")\n",
        "\n",
        "model.enable_input_require_grads()\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_eval,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# ✅ Save model\n",
        "model.save_pretrained(\"/content/drive/MyDrive/deepseek-7b-recipe-lora2-v3\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/deepseek-7b-recipe-lora2-v3\")\n",
        "print(\"✅ Training complete. Saved to lora2-v3.\")\n"
      ],
      "metadata": {
        "id": "JbMZv_krIPIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "from unsloth import FastLanguageModel\n",
        "\n",
        "# Load your model and tokenizer (assuming these are already done)\n",
        "model_path = \"/content/drive/MyDrive/deepseek-7b-recipe-lora2-v3\"\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=model_path,\n",
        "    max_seq_length=1024,\n",
        "    dtype=torch.bfloat16,\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# Inference function using greedy decoding (deterministic output)\n",
        "def generate_recipe(prompt):\n",
        "    # Use greedy decoding for inference (no randomness)\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    output = model.generate(inputs[\"input_ids\"], max_length=512, do_sample=False, temperature=0.7)\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# Inference function using sampling (randomized output)\n",
        "def generate_recipe_with_sampling(prompt):\n",
        "    # Use sampling for inference (if you'd like variability)\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    output = model.generate(inputs[\"input_ids\"], max_length=512, do_sample=True, top_p=0.95, temperature=0.7)\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# Test Cases for Recipe Generation\n",
        "\n",
        "test_cases = [\n",
        "    {\n",
        "        'input_prompt': \"Generate a recipe using ONLY the following ingredients: carrot, chicken, rice, garlic, olive oil. Do not include the following allergens: peanut. Ensure the recipe follows these dietary preferences: gluten free, dairy free. Include title, ingredients, and detailed step-by-step instructions.\"\n",
        "    },\n",
        "    {\n",
        "        'input_prompt': \"Generate a recipe using ONLY the following ingredients: tomatoes, basil, mozzarella. Do not include the following allergens: gluten. Ensure the recipe follows these dietary preferences: vegetarian, gluten free. Include title, ingredients, and detailed step-by-step instructions.\"\n",
        "    },\n",
        "    {\n",
        "        'input_prompt': \"Generate a recipe using ONLY the following ingredients: spinach, feta cheese, olive oil, lemon. Do not include the following allergens: dairy. Ensure the recipe follows these dietary preferences: vegan. Include title, ingredients, and detailed step-by-step instructions.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Running the test cases and generating recipes\n",
        "\n",
        "for i, test_case in enumerate(test_cases, start=1):\n",
        "    print(f\"\\nTest Case {i} (Greedy Decoding):\")\n",
        "    print(\"=\" * 50)\n",
        "    generated_recipe = generate_recipe(test_case['input_prompt'])\n",
        "    print(generated_recipe)\n",
        "\n",
        "    print(\"\\nTest Case {i} (Sampling Decoding):\")\n",
        "    print(\"=\" * 50)\n",
        "    generated_recipe_sampling = generate_recipe_with_sampling(test_case['input_prompt'])\n",
        "    print(generated_recipe_sampling)\n",
        "    print(\"=\" * 50)\n"
      ],
      "metadata": {
        "id": "1rwvgTbuU-sV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}